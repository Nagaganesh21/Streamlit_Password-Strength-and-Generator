{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:30:21.933560Z",
     "start_time": "2024-03-04T12:30:21.430487Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = r'D:\\ML and DL Coading practce\\Projects with Deployments\\Streamlit Cloud\\PassWord Strength - NLP\\dataset\\data.csv'\n",
    "#data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = pd.read_csv(path, on_bad_lines='skip')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:30:34.612019Z",
     "start_time": "2024-03-04T12:30:34.212690Z"
    }
   },
   "id": "34ef038dc0385a7c",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      password  strength\n0     kzde5577         1\n1     kino3434         1\n2    visi7k1yr         1\n3     megzy123         1\n4  lamborghin1         1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>password</th>\n      <th>strength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>kzde5577</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>kino3434</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>visi7k1yr</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>megzy123</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>lamborghin1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:30:35.563110Z",
     "start_time": "2024-03-04T12:30:35.539597Z"
    }
   },
   "id": "ceaa71d4ee8a3011",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 2, 0], dtype=int64)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['strength'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:30:37.527599Z",
     "start_time": "2024-03-04T12:30:37.501601Z"
    }
   },
   "id": "7962e7f43db243ca",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "strength\n1    496801\n0     89702\n2     83137\nName: count, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['strength'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:30:38.624195Z",
     "start_time": "2024-03-04T12:30:38.604809Z"
    }
   },
   "id": "b8fb13594332824c",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 669640 entries, 0 to 669639\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   password  669639 non-null  object\n",
      " 1   strength  669640 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 10.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:30:39.715979Z",
     "start_time": "2024-03-04T12:30:39.681986Z"
    }
   },
   "id": "6220411fa4b2f5f3",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "password    1\nstrength    0\ndtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:30:41.587290Z",
     "start_time": "2024-03-04T12:30:41.553306Z"
    }
   },
   "id": "eeffe55bb85c6d91",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = data.dropna(axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:30:43.586835Z",
     "start_time": "2024-03-04T12:30:43.514384Z"
    }
   },
   "id": "4e247ae67d36d176",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "password    0\nstrength    0\ndtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:30:48.585950Z",
     "start_time": "2024-03-04T12:30:48.546444Z"
    }
   },
   "id": "fe6838b99ed5a7b7",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = data['password'].values\n",
    "y = data['strength'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:30:50.941360Z",
     "start_time": "2024-03-04T12:30:50.929360Z"
    }
   },
   "id": "cd4a616b1ac56178",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kzde5577' 'kino3434' 'visi7k1yr' ... '184520socram' 'marken22a'\n",
      " 'fxx4pw4g']\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:30:52.379714Z",
     "start_time": "2024-03-04T12:30:52.359542Z"
    }
   },
   "id": "5c45a35e0d8701a6",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:30:53.972206Z",
     "start_time": "2024-03-04T12:30:53.953229Z"
    }
   },
   "id": "9513929bf4ee82f2",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['kzde5577', 'kino3434', 'visi7k1yr', ..., '184520socram',\n       'marken22a', 'fxx4pw4g'], dtype=object)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:30:55.041255Z",
     "start_time": "2024-03-04T12:30:55.022541Z"
    }
   },
   "id": "cae9b12a3d67cc1b",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#split string to individual character\n",
    "def word_split(text):\n",
    "    character = []\n",
    "    for ch in text:\n",
    "        character.append(ch)\n",
    "    return character"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "906f495748a9a6fd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "word_split('test')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b3d8dabbc73a63b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tokenizer = TfidfVectorizer(tokenizer=word_split)\n",
    "\n",
    "X1 = tokenizer.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afe56235e424d5fd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X1.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbb518bd00d2c67e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "294e41bd54a97ede",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tokenizer, open('tokenizer.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6de5e88b50ec7bf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X1[0].T.todense(), index=tokenizer.get_feature_names_out(), columns= ['TF-IDF'])\n",
    "df.sort_values(by=['TF-IDF'], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf9c0b75db59d6cd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, random_state=50, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3d9cfb2e696be49",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f'the shape of X_train is {X_train.shape} and the shape of y_train is {y_train.shape}')\n",
    "print(f'the shape of X_test is {X_test.shape} and the shape of y_test is {y_test.shape}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21b7c37d1b9109d0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(multi_class='multinomial')\n",
    "clf.fit(X_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85899bf1560a09a3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a0b790fef75f7d7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#svae the model\n",
    "import joblib\n",
    "\n",
    "# Assuming clf is the trained model\n",
    "joblib.dump(clf, 'logistic_regression_model.pkl')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53bf3811f6f80a7a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dt = np.array(['%$DFGD@#$'])\n",
    "dt1 = tokenizer.transform(dt)\n",
    "clf.predict(dt1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65e518eff8ee65b5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Ask the user to input a password\n",
    "user_password = input(\"Enter your password: \")\n",
    "\n",
    "# Preprocess the input password\n",
    "X_input = tokenizer.transform([user_password])\n",
    "\n",
    "# Predict the strength of the password\n",
    "predicted_strength = clf.predict(X_input)[0]\n",
    "\n",
    "if predicted_strength == 0:\n",
    "    print(\"The password is very weak.\")\n",
    "elif predicted_strength == 1:\n",
    "    print(\"The password is medium.\")\n",
    "else:\n",
    "    print(\"The password is strong.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5db54c9e1c4b3ddb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "# Function to generate a random password\n",
    "def generate_password(length=8):\n",
    "    characters = string.ascii_letters + string.digits + string.punctuation\n",
    "    password = ''.join(random.choice(characters) for _ in range(length))\n",
    "    return password\n",
    "\n",
    "# Function to check the strength of a password using your trained model\n",
    "def check_password_strength(password):\n",
    "    # Preprocess the password\n",
    "    X_input = tokenizer.transform([password])\n",
    "    # Predict the strength\n",
    "    predicted_strength = clf.predict(X_input)[0]\n",
    "    return predicted_strength\n",
    "\n",
    "# Generate a strong password\n",
    "def generate_strong_password(min_length=10):\n",
    "    while True:\n",
    "        password = generate_password(min_length)\n",
    "        predicted_strength = check_password_strength(password)\n",
    "        if predicted_strength == 2:  # Strong password\n",
    "            return password\n",
    "\n",
    "# Example usage\n",
    "strong_password = generate_strong_password()\n",
    "print(\"Generated strong password:\", strong_password)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12bdbdb77c16797b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### without word_split fnction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45db69e396e4889b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ML and DL Coading practce\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "\n",
    "# Define word_split function within the TfidfVectorizer initialization\n",
    "tokenizer2 = TfidfVectorizer(tokenizer=lambda text: [ch for ch in text])\n",
    "\n",
    "X2 = tokenizer2.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:31:10.193249Z",
     "start_time": "2024-03-04T12:31:05.047511Z"
    }
   },
   "id": "7dc43312790d72c0",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(669639, 153)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:31:10.209106Z",
     "start_time": "2024-03-04T12:31:10.196153Z"
    }
   },
   "id": "9c7539dea6576ee8",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      TF-IDF\n7   0.591303\n5   0.566899\nz   0.335926\nk   0.292247\nd   0.285631\n..       ...\n\\   0.000000\n]   0.000000\n^   0.000000\n_   0.000000\n™   0.000000\n\n[153 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TF-IDF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>0.591303</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.566899</td>\n    </tr>\n    <tr>\n      <th>z</th>\n      <td>0.335926</td>\n    </tr>\n    <tr>\n      <th>k</th>\n      <td>0.292247</td>\n    </tr>\n    <tr>\n      <th>d</th>\n      <td>0.285631</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>\\</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>]</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>^</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>_</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>™</th>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>153 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(X2[0].T.todense(), index=tokenizer2.get_feature_names_out(), columns= ['TF-IDF'])\n",
    "df2.sort_values(by=['TF-IDF'], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:31:25.559537Z",
     "start_time": "2024-03-04T12:31:25.544501Z"
    }
   },
   "id": "621b3d312ff7d9db",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ML and DL Coading practce\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "\n",
    "# Define a function for character-level tokenization\n",
    "def tokenize_chars(text):\n",
    "    return [ch for ch in text]\n",
    "\n",
    "# Initialize TfidfVectorizer with the custom tokenizer function\n",
    "tokenizer2 = TfidfVectorizer(tokenizer=tokenize_chars)\n",
    "\n",
    "X2 = tokenizer2.fit_transform(X)\n",
    "# Pickle the tokenizer\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer2, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T12:35:57.344192Z",
     "start_time": "2024-03-04T12:35:53.508603Z"
    }
   },
   "id": "141b989f9452fcba",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "45875819f822337f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
